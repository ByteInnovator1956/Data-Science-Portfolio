{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e7edff-8194-4959-aeef-d0442a81bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: label\n",
      "Flood                               4033\n",
      "Storm                               2563\n",
      "Road                                1917\n",
      "Water                                977\n",
      "Epidemic                             877\n",
      "Earthquake                           641\n",
      "Mass movement (wet)                  458\n",
      "Extreme temperature                  438\n",
      "Explosion (Industrial)               432\n",
      "Air                                  426\n",
      "Fire (Miscellaneous)                 415\n",
      "Drought                              399\n",
      "Wildfire                             304\n",
      "Rail                                 241\n",
      "Miscellaneous accident (General)     183\n",
      "Explosion (Miscellaneous)            159\n",
      "Collapse (Miscellaneous)             149\n",
      "Collapse (Industrial)                146\n",
      "Volcanic activity                    121\n",
      "Fire (Industrial)                    108\n",
      "Industrial accident (General)        100\n",
      "Gas leak                              34\n",
      "Infestation                           29\n",
      "Chemical spill                        23\n",
      "Poisoning                             20\n",
      "Mass movement (dry)                   13\n",
      "Oil spill                              5\n",
      "Glacial lake outburst flood            4\n",
      "Radiation                              2\n",
      "Impact                                 1\n",
      "Animal incident                        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model trained successfully!\n",
      "Accuracy: 0.9967148488830486\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                             Air       1.00      1.00      1.00        85\n",
      "                  Chemical spill       1.00      1.00      1.00         4\n",
      "           Collapse (Industrial)       1.00      1.00      1.00        22\n",
      "        Collapse (Miscellaneous)       1.00      1.00      1.00        32\n",
      "                         Drought       1.00      0.98      0.99        88\n",
      "                      Earthquake       1.00      1.00      1.00       127\n",
      "                        Epidemic       1.00      0.99      1.00       196\n",
      "          Explosion (Industrial)       1.00      1.00      1.00        63\n",
      "       Explosion (Miscellaneous)       1.00      1.00      1.00        32\n",
      "             Extreme temperature       1.00      0.99      1.00       102\n",
      "               Fire (Industrial)       1.00      1.00      1.00        21\n",
      "            Fire (Miscellaneous)       1.00      1.00      1.00        72\n",
      "                           Flood       0.99      1.00      1.00       832\n",
      "                        Gas leak       1.00      1.00      1.00         6\n",
      "     Glacial lake outburst flood       0.00      0.00      0.00         2\n",
      "                          Impact       0.00      0.00      0.00         1\n",
      "   Industrial accident (General)       0.95      1.00      0.97        19\n",
      "                     Infestation       1.00      1.00      1.00         4\n",
      "             Mass movement (dry)       1.00      1.00      1.00         2\n",
      "             Mass movement (wet)       1.00      1.00      1.00       103\n",
      "Miscellaneous accident (General)       1.00      1.00      1.00        28\n",
      "                       Oil spill       0.00      0.00      0.00         1\n",
      "                       Poisoning       1.00      1.00      1.00         4\n",
      "                       Radiation       0.00      0.00      0.00         1\n",
      "                            Rail       1.00      1.00      1.00        46\n",
      "                            Road       1.00      1.00      1.00       376\n",
      "                           Storm       0.99      1.00      1.00       515\n",
      "               Volcanic activity       1.00      1.00      1.00        32\n",
      "                           Water       1.00      1.00      1.00       171\n",
      "                        Wildfire       1.00      0.98      0.99        57\n",
      "\n",
      "                        accuracy                           1.00      3044\n",
      "                       macro avg       0.86      0.86      0.86      3044\n",
      "                    weighted avg       1.00      1.00      1.00      3044\n",
      "\n",
      "\n",
      "üíæ Model and vectorizer saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"data/clean_disaster_text_dataset.csv\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Label distribution:\", df[\"label\"].value_counts())\n",
    "\n",
    "# Remove stratify parameter since some classes have too few samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42\n",
    "    # Removed stratify=df[\"label\"] to fix the error\n",
    ")\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000, multi_class='auto')\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(\"‚úÖ Model trained successfully!\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model + vectorizer\n",
    "joblib.dump(model, \"models/disaster_classifier5.pkl\")\n",
    "joblib.dump(vectorizer, \"models/disaster_vectorizer3.pkl\")\n",
    "\n",
    "print(\"\\nüíæ Model and vectorizer saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b237dd4b-816c-4c58-b162-8314b6f0c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clean dataset ready!\n",
      "Shape: (15219, 2)\n",
      "\n",
      "Sample:\n",
      "                                                 text    label\n",
      "0  Djibouti Ali Sabieh, Dikhil, Djibouti, Obock, ...  Drought\n",
      "1  Sudan Northern Darfur, Northern Kordofan, Red ...  Drought\n",
      "2  Somalia Ceel Barde, Rab Dhuure, Tayeeglow, Xud...  Drought\n",
      "3  Angola Calulo Technological Transport Road Roa...     Road\n",
      "4  Angola Dombre Grande village (Baia Farta distr...    Flood\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"public_emdat_project.csv\", encoding='latin1')\n",
    "\n",
    "# Select relevant columns\n",
    "text_columns = [\"Country\", \"Location\", \"Disaster Group\", \"Disaster Subgroup\", \n",
    "                \"Disaster Type\", \"Disaster Subtype\", \"Event Name\", \n",
    "                \"Origin\", \"Region\", \"Subregion\"]\n",
    "label_column = \"Disaster Type\"\n",
    "\n",
    "# Combine text fields into a single column\n",
    "df[\"text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "# Drop missing labels and duplicates\n",
    "df = df.dropna(subset=[label_column])\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "# Keep only text + label columns\n",
    "df_final = df[[\"text\", label_column]].rename(columns={label_column: \"label\"})\n",
    "\n",
    "print(\"‚úÖ Clean dataset ready!\")\n",
    "print(\"Shape:\", df_final.shape)\n",
    "print(\"\\nSample:\\n\", df_final.head())\n",
    "\n",
    "# Optional: Save for later use\n",
    "df_final.to_csv(\"data/clean_disaster_text_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b63559-c3ae-45c7-a721-b98aeba6520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running cleaning.py to generate cleaned dataset...\n",
      "\n",
      "‚úÖ cleaning.py executed successfully!\n",
      "\n",
      "‚úÖ Cleaned dataset loaded successfully!\n",
      "Shape: (272, 4)\n",
      "Columns: ['source', 'timestamp', 'clean_text', 'location'] \n",
      "\n",
      "‚úÖ Multi-class model and vectorizer loaded successfully!\n",
      "\n",
      "üíæ Final multi-class disaster data saved to data\\final_disaster_data.csv\n",
      "üéØ Model processing completed successfully!\n",
      "\n",
      "Sample of final predictions:\n",
      "\n",
      "                   timestamp  \\\n",
      "0  2025-11-09 08:04:06+00:00   \n",
      "1  2025-11-09 07:50:19+00:00   \n",
      "2  2025-11-09 07:44:21+00:00   \n",
      "3  2025-11-09 07:35:00+00:00   \n",
      "4  2025-11-09 07:30:17+00:00   \n",
      "\n",
      "                                                text  \\\n",
      "0  philippines braces for super typhoon with 9000...   \n",
      "1  2025 sks weekly climate change global warming ...   \n",
      "2  nearly 1 million filipinos evacuate as super t...   \n",
      "3  are we entering a golden age of nuclear power ...   \n",
      "4  dani rodrik the world needs a new economic pla...   \n",
      "\n",
      "                                      location predicted_disaster_type  \\\n",
      "0  Philippines, Luzon, Super Typhoon Fung-wong                   Storm   \n",
      "1                                      Unknown                   Flood   \n",
      "2              Philippines, Super Typhoon Fung                   Storm   \n",
      "3                                           UK                   Flood   \n",
      "4                                      Unknown                   Storm   \n",
      "\n",
      "   confidence          reason  \n",
      "0        0.50  keyword assist  \n",
      "1        0.26           model  \n",
      "2        0.80  keyword assist  \n",
      "3        0.21           model  \n",
      "4        0.23           model  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import subprocess\n",
    "\n",
    "# === 0Ô∏è‚É£ Run cleaning.py to generate cleaned dataset ===\n",
    "cleaning_script_path = os.path.join(\"model_build\", \"cleaning.py\")\n",
    "print(\"üöÄ Running cleaning.py to generate cleaned dataset...\\n\")\n",
    "try:\n",
    "    subprocess.run([\"python\", cleaning_script_path], check=True)\n",
    "    print(\"‚úÖ cleaning.py executed successfully!\\n\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    raise RuntimeError(f\"‚ùå Error while running cleaning.py: {e}\")\n",
    "\n",
    "# === 1Ô∏è‚É£ Load cleaned dataset ===\n",
    "cleaned_file_path = os.path.join(\"data\", \"cleaned_dataset.csv\")\n",
    "if not os.path.exists(cleaned_file_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Cleaned dataset not found at {cleaned_file_path}\")\n",
    "\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "print(\"‚úÖ Cleaned dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist(), \"\\n\")\n",
    "\n",
    "# === 2Ô∏è‚É£ Load pre-trained multi-class model ===\n",
    "model_file = os.path.join(\"models\", \"disaster_classifier5.pkl\")\n",
    "vectorizer_file = os.path.join(\"models\", \"disaster_vectorizer3.pkl\")\n",
    "\n",
    "try:\n",
    "    model = joblib.load(model_file)\n",
    "    vectorizer = joblib.load(vectorizer_file)\n",
    "    print(\"‚úÖ Multi-class model and vectorizer loaded successfully!\\n\")\n",
    "except:\n",
    "    raise FileNotFoundError(\"‚ùå New multi-class model/vectorizer not found!\")\n",
    "\n",
    "# === 3Ô∏è‚É£ Optional keyword list (for hybrid boost) ===\n",
    "DISASTER_KEYWORDS = [\n",
    "    \"earthquake\", \"flood\", \"cyclone\", \"hurricane\", \"storm\", \"tornado\", \"tsunami\",\n",
    "    \"landslide\", \"disaster\", \"wildfire\", \"volcano\", \"eruption\", \"drought\",\n",
    "    \"avalanche\", \"rescue\", \"collapsed\", \"aftershock\", \"damaged\", \"mudslide\", \"explosion\"\n",
    "]\n",
    "\n",
    "# === 4Ô∏è‚É£ Prediction function ===\n",
    "def classify_disaster(text):\n",
    "    cleaned = re.sub(r'\\s+', ' ', str(text).strip().lower())\n",
    "    tfidf_input = vectorizer.transform([cleaned])\n",
    "    pred_label = model.predict(tfidf_input)[0]\n",
    "    probs = model.predict_proba(tfidf_input)[0]\n",
    "    confidence = round(float(max(probs)), 2)\n",
    "\n",
    "    keyword_flag = any(kw in cleaned for kw in DISASTER_KEYWORDS)\n",
    "    reason = \"keyword assist\" if keyword_flag else \"model\"\n",
    "\n",
    "    return pred_label, confidence, reason\n",
    "\n",
    "# === 5Ô∏è‚É£ Apply classification safely ===\n",
    "final_results = []\n",
    "for _, row in df.iterrows():\n",
    "    # pick the right column (clean_text or text)\n",
    "    text_data = str(row.get(\"clean_text\") or row.get(\"text\") or \"\").strip()\n",
    "    if not text_data or text_data.lower() == \"nan\":\n",
    "        continue  # skip empty rows\n",
    "\n",
    "    pred, conf, reason = classify_disaster(text_data)\n",
    "    final_results.append({\n",
    "    \"timestamp\": row.get(\"timestamp\", \"\"),\n",
    "    \"text\": row[\"clean_text\"],\n",
    "    \"location\": row.get(\"location\", \"Unknown\"),\n",
    "    \"predicted_disaster_type\": pred,\n",
    "    \"confidence\": conf,\n",
    "    \"reason\": reason\n",
    "})\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame(final_results)\n",
    "final_df = final_df.sort_values(by=\"timestamp\", ascending=False)\n",
    "\n",
    "# === 6Ô∏è‚É£ Save final CSV ===\n",
    "final_csv_path = os.path.join(\"data\", \"final_disaster_data.csv\")\n",
    "final_df.to_csv(final_csv_path, index=False)\n",
    "print(f\"üíæ Final multi-class disaster data saved to {final_csv_path}\")\n",
    "print(\"üéØ Model processing completed successfully!\")\n",
    "\n",
    "# Optional sanity check\n",
    "print(\"\\nSample of final predictions:\\n\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0509ba-89fc-4d03-8479-79a657950c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of final predictions:\n",
      "\n",
      "                   timestamp  \\\n",
      "0  2025-11-09 08:04:06+00:00   \n",
      "1  2025-11-09 07:50:19+00:00   \n",
      "2  2025-11-09 07:44:21+00:00   \n",
      "3  2025-11-09 07:35:00+00:00   \n",
      "4  2025-11-09 07:30:17+00:00   \n",
      "\n",
      "                                                text  \\\n",
      "0  philippines braces for super typhoon with 9000...   \n",
      "1  2025 sks weekly climate change global warming ...   \n",
      "2  nearly 1 million filipinos evacuate as super t...   \n",
      "3  are we entering a golden age of nuclear power ...   \n",
      "4  dani rodrik the world needs a new economic pla...   \n",
      "\n",
      "                                      location predicted_disaster_type  \\\n",
      "0  Philippines, Luzon, Super Typhoon Fung-wong                   Storm   \n",
      "1                                      Unknown                   Flood   \n",
      "2              Philippines, Super Typhoon Fung                   Storm   \n",
      "3                                           UK                   Flood   \n",
      "4                                      Unknown                   Storm   \n",
      "\n",
      "   confidence          reason  \n",
      "0        0.50  keyword assist  \n",
      "1        0.26           model  \n",
      "2        0.80  keyword assist  \n",
      "3        0.21           model  \n",
      "4        0.23           model  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/final_disaster_data.csv\")\n",
    "\n",
    "# 1Ô∏è‚É£ Check top 5 rows\n",
    "print(\"Sample of final predictions:\\n\")\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba46af6b-2c4f-48c3-be66-5990d21cefc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>predicted_disaster_type</th>\n",
       "      <th>confidence</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-09 08:04:06+00:00</td>\n",
       "      <td>philippines braces for super typhoon with 9000...</td>\n",
       "      <td>Philippines, Luzon, Super Typhoon Fung-wong</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.50</td>\n",
       "      <td>keyword assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09 07:50:19+00:00</td>\n",
       "      <td>2025 sks weekly climate change global warming ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Flood</td>\n",
       "      <td>0.26</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09 07:44:21+00:00</td>\n",
       "      <td>nearly 1 million filipinos evacuate as super t...</td>\n",
       "      <td>Philippines, Super Typhoon Fung</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.80</td>\n",
       "      <td>keyword assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09 07:35:00+00:00</td>\n",
       "      <td>are we entering a golden age of nuclear power ...</td>\n",
       "      <td>UK</td>\n",
       "      <td>Flood</td>\n",
       "      <td>0.21</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09 07:30:17+00:00</td>\n",
       "      <td>dani rodrik the world needs a new economic pla...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.23</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  \\\n",
       "0  2025-11-09 08:04:06+00:00   \n",
       "1  2025-11-09 07:50:19+00:00   \n",
       "2  2025-11-09 07:44:21+00:00   \n",
       "3  2025-11-09 07:35:00+00:00   \n",
       "4  2025-11-09 07:30:17+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  philippines braces for super typhoon with 9000...   \n",
       "1  2025 sks weekly climate change global warming ...   \n",
       "2  nearly 1 million filipinos evacuate as super t...   \n",
       "3  are we entering a golden age of nuclear power ...   \n",
       "4  dani rodrik the world needs a new economic pla...   \n",
       "\n",
       "                                      location predicted_disaster_type  \\\n",
       "0  Philippines, Luzon, Super Typhoon Fung-wong                   Storm   \n",
       "1                                      Unknown                   Flood   \n",
       "2              Philippines, Super Typhoon Fung                   Storm   \n",
       "3                                           UK                   Flood   \n",
       "4                                      Unknown                   Storm   \n",
       "\n",
       "   confidence          reason  \n",
       "0        0.50  keyword assist  \n",
       "1        0.26           model  \n",
       "2        0.80  keyword assist  \n",
       "3        0.21           model  \n",
       "4        0.23           model  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93dd5a-f8f4-4c2e-b95d-5c706b893630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
